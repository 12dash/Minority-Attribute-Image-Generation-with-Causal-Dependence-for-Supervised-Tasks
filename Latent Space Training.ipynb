{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc776022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from resnet import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize, CenterCrop\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from bgm import *\n",
    "from sagan import *\n",
    "from causal_model import *\n",
    "from load_data import *\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f19f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10351c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainImageDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.folder= [folder+i for i in os.listdir(folder) if '.pt' in i]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.folder)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        (z,y,attr) = torch.load(self.folder[index])\n",
    "        return (z,y,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36043918",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "cols = ['Smiling', 'Male', 'High_Cheekbones', 'Mouth_Slightly_Open', 'Narrow_Eyes', 'Chubby']\n",
    "dest_dir = 'synthetic_latent_dataset'\n",
    "train_folder = f'{dest_dir}/train/'\n",
    "test_folder = f'{dest_dir}/test/'\n",
    "\n",
    "train_data = TrainImageDataset(train_folder)\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size,shuffle = True)\n",
    "\n",
    "test_data = TrainImageDataset(test_folder)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22fb4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "for z, y, attr in train_dataloader:\n",
    "    print(z.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387da975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentModel(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LatentModel(latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "094a9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_weighted_loss(y_hat, y, weights):\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss = loss * weights\n",
    "    return loss.sum() / weights.sum()\n",
    "    #return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "num = len(train_dataloader.dataset)//batch_size + 1\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1caa9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae3e5b198a2493e86ab379ab0f80b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7b5abd2ec04bdb8c0277fd281b24c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(z)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(2):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_dataloader), total = num):\n",
    "        z, y, attr = data\n",
    "        z, y, attr = z.to(device), y.to(device), attr.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(z)\n",
    "        loss = criterion(outputs, y.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / num:.3f}')\n",
    "          \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fdc0f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00e90a82e894e48b8ca6349b5c224e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#class:{attr:}\n",
    "correct_pred = {0:{0:0,1:0},1:{0:0,1:0}}\n",
    "total_pred = {0:{0:0,1:0},1:{0:0,1:0}}\n",
    "model.eval()\n",
    "label_l = []\n",
    "pred_l = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader, total=len(test_dataloader.dataset)//batch_size):\n",
    "        z, y, attr = data\n",
    "        z, y, attr = z.to(device), y.to(device), attr.to(device)\n",
    "        outputs= model(z)\n",
    "        predictions = torch.round(torch.sigmoid(outputs))\n",
    "        for label, prediction, attr in zip(y, predictions, attr):\n",
    "            if label == prediction:\n",
    "                correct_pred[label.item()][attr.item()] += 1\n",
    "            total_pred[label.item()][attr.item()] += 1\n",
    "            label_l.append(label.item())\n",
    "            pred_l.append(prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709613ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0 , attr: 0: 82.67673048600884 total: 5432  \n",
      "Accuracy for class: 0 , attr: 1: 94.1944556046605 total: 4978  \n",
      "Accuracy for class: 1 , attr: 0: 93.77819256494011 total: 6429  \n",
      "Accuracy for class: 1 , attr: 1: 78.98275358082432 total: 3421  \n"
     ]
    }
   ],
   "source": [
    "for classname, correct_counts in correct_pred.items():\n",
    "    for attr_name, correct_count in correct_counts.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname][attr_name] if total_pred[classname][attr_name] > 0 else 0\n",
    "        print(f'Accuracy for class: {classname} , attr: {attr_name}: {accuracy} total: {total_pred[classname][attr_name]}  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55dac67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
