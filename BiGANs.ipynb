{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e05e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense, Conv2D, LeakyReLU, Conv2DTranspose, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad50856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(img_size, latent_dim):\n",
    "    z = Input(latent_dim)\n",
    "    x = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(z)\n",
    "    x = Conv2D(512, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2D(256, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    x = Conv2DTranspose(img_size[-1], (3,3),strides=(2,2),padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    return Model(z, x)\n",
    "\n",
    "def build_encoder(img_size, latent_dim):\n",
    "    x = Input(img_size)\n",
    "    y = Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(x)\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(latent_dim[-1], (3,3), strides=(2,2), padding=\"same\")(y)\n",
    "    return Model(x,y)\n",
    "\n",
    "def build_discriminator(img_size, latent_dim):\n",
    "    x = Input(img_size)\n",
    "    z = Input(latent_dim)\n",
    "    _z = Flatten()(z)\n",
    "    _z = Dense(img_size[0]*img_size[1]*img_size[2])(_z)\n",
    "    _z = Reshape(img_size)(_z)\n",
    "\n",
    "    y = Concatenate()([x,_z])\n",
    "    y = Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(1024, (3, 3), strides=(2, 2), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Conv2D(1024, (3, 3), padding=\"same\", activation = tf.nn.leaky_relu)(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dense(1)(y)\n",
    "    return Model([x, z], [y])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72114f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, img_size = 64, batch_size = 1):\n",
    "    df = tf.keras.utils.image_dataset_from_directory(directory = data_dir, \n",
    "                                                     labels = None, \n",
    "                                                     batch_size= None,\n",
    "                                                     image_size = (img_size, img_size),\n",
    "                                                     seed = 42)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b80dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2560 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 03:14:54.518088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:54.535670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:54.538655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:54.543507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 03:14:54.543946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:54.547694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:54.550816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:55.161302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:55.164180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:55.167010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-24 03:14:55.170447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"sample_data/\"\n",
    "img_dim = 64\n",
    "train_ds = load_dataset(data_folder+\"img\", img_size = img_dim, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960b58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_norm(x):\n",
    "    return (x*2)/255.0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad12ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = (2, 2, 128)\n",
    "img_size = (img_dim, img_dim, 3)\n",
    "\n",
    "enc = build_encoder(img_size, latent_dim)\n",
    "gen = build_generator(img_size, latent_dim)\n",
    "disc = build_discriminator(img_size, latent_dim)\n",
    "\n",
    "g_opt = Adam(learning_rate = 1e-4)\n",
    "e_opt = Adam(learning_rate = 1e-4)\n",
    "d_opt = Adam(learning_rate = 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f29801",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(train_ds)\n",
    "\n",
    "train_ds = train_ds.map(apply_norm)\n",
    "train_ds = tfds.as_numpy(train_ds)\n",
    "\n",
    "z_train = np.random.uniform(-1.0, 1.0, (num, )+latent_dim).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2264face",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "t = list(zip(train_ds, z_train))\n",
    "random.shuffle(t)\n",
    "train_ds, z_train = zip(*t)\n",
    "\n",
    "train_ds = np.array(train_ds)\n",
    "z_train = np.array(z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96374930",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f343ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_ds.reshape(-1, batch_size, img_dim, img_dim, 3)\n",
    "z_train = z_train.reshape(-1, batch_size, latent_dim[0], latent_dim[1], latent_dim[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e8012bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e99728d9e1a4a1ea6d499aacaa4b6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Desc loss : 13.1535528820\t Gen Loss : 1373.4470348358\t Enc Loss : 2590.7647881508\n",
      "[1] Desc loss : 14.4569167111\t Gen Loss : 1659.8978767395\t Enc Loss : 3480.3543143272\n",
      "[2] Desc loss : 14.4211983825\t Gen Loss : 1314.9784069061\t Enc Loss : 2616.6749918461\n",
      "[3] Desc loss : 13.5996029071\t Gen Loss : 1399.2598161697\t Enc Loss : 3255.1986703873\n",
      "[4] Desc loss : 13.1622095953\t Gen Loss : 1690.7522020340\t Enc Loss : 2733.8005280495\n",
      "[5] Desc loss : 13.8165076920\t Gen Loss : 1625.9779486656\t Enc Loss : 2706.8531537056\n",
      "[6] Desc loss : 11.1726483789\t Gen Loss : 1636.6813797951\t Enc Loss : 2678.0524311066\n",
      "[7] Desc loss : 17.4227727035\t Gen Loss : 1696.0082964897\t Enc Loss : 4110.1270351410\n",
      "[8] Desc loss : 15.4284977469\t Gen Loss : 1781.7902662754\t Enc Loss : 2869.8817496300\n",
      "[9] Desc loss : 16.2349460035\t Gen Loss : 1335.8426141739\t Enc Loss : 3584.7620216608\n",
      "[10] Desc loss : 15.2249684765\t Gen Loss : 1341.9857816696\t Enc Loss : 2998.4582509995\n",
      "[11] Desc loss : 16.4540030561\t Gen Loss : 1405.3278849125\t Enc Loss : 3600.0602412224\n",
      "[12] Desc loss : 12.4994613112\t Gen Loss : 1674.3105859756\t Enc Loss : 2744.2828950882\n",
      "[13] Desc loss : 16.0948088324\t Gen Loss : 1444.5687603951\t Enc Loss : 3410.2137837410\n",
      "[14] Desc loss : 18.6690042918\t Gen Loss : 1760.4603514671\t Enc Loss : 2628.0352187157\n",
      "[15] Desc loss : 12.1521672097\t Gen Loss : 1628.0143752098\t Enc Loss : 3193.0657622814\n",
      "[16] Desc loss : 13.9398958397\t Gen Loss : 1593.9192357063\t Enc Loss : 2797.6748354435\n",
      "[17] Desc loss : 14.2893814842\t Gen Loss : 1527.9039955139\t Enc Loss : 2771.3616027832\n",
      "[18] Desc loss : 22.7636707301\t Gen Loss : 1757.5403943062\t Enc Loss : 3314.8159768581\n",
      "[19] Desc loss : 14.9220733162\t Gen Loss : 1650.7659115791\t Enc Loss : 2913.6058080196\n",
      "[20] Desc loss : 13.8205097300\t Gen Loss : 1651.1029911041\t Enc Loss : 2386.1116240025\n",
      "[21] Desc loss : 15.8303572799\t Gen Loss : 1530.3996071815\t Enc Loss : 2588.7065143585\n",
      "[22] Desc loss : 12.0858255022\t Gen Loss : 1545.2191081047\t Enc Loss : 2714.2281258106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_27182/3674983049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mgen_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdisc_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0menc_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DBackpropInputGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m           data_format=op.get_attr(\"data_format\").decode()),\n\u001b[0m\u001b[1;32m     51\u001b[0m       gen_nn_ops.conv2d(\n\u001b[1;32m     52\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs), desc='Total'):\n",
    "    \n",
    "    running_loss = [0,0,0]\n",
    "    num_steps = num//batch_size\n",
    "    \n",
    "    perm = np.random.permutation(X_train.shape[0])\n",
    "    \n",
    "    X_train = X_train[perm]\n",
    "    z_train = np.random.uniform(-1.0, 1.0, (num, )+latent_dim).astype(\"float32\")\n",
    "    z_train = z_train.reshape(-1, batch_size, latent_dim[0], latent_dim[1], latent_dim[2])\n",
    "    \n",
    "    for steps in range(0, num_steps):\n",
    "        x_batch = X_train[steps]\n",
    "        z_batch = z_train[steps]\n",
    "        \n",
    "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:      \n",
    "            fake_img = gen(z_batch)\n",
    "            fake_z = enc(x_batch)\n",
    "\n",
    "            preds = disc([tf.concat([fake_img, x_batch], axis = 0) , tf.concat([z_batch, fake_z], axis = 0)])\n",
    "            pred_gen, pred_enc = tf.split(preds, 2, axis = 0)\n",
    "            \n",
    "            gen_loss = tf.reduce_mean(tf.nn.softplus(-pred_gen))\n",
    "            enc_loss = tf.reduce_mean(tf.nn.softplus(pred_enc))\n",
    "            \n",
    "            disc_loss = tf.reduce_mean(tf.nn.softplus(pred_gen)) + tf.reduce_mean(tf.nn.softplus(-pred_enc))\n",
    "\n",
    "        gen_grad = tape.gradient(gen_loss, gen.trainable_variables)        \n",
    "        disc_grad = tape.gradient(disc_loss, disc.trainable_variables)\n",
    "        enc_grad = tape.gradient(enc_loss, enc.trainable_variables)\n",
    "\n",
    "        g_opt.apply_gradients(zip(gen_grad,gen.trainable_variables))\n",
    "        e_opt.apply_gradients(zip(enc_grad,enc.trainable_variables))\n",
    "        d_opt.apply_gradients(zip(disc_grad,disc.trainable_variables))\n",
    "\n",
    "        running_loss[0] += disc_loss.numpy()\n",
    "        running_loss[1] += gen_loss.numpy()\n",
    "        running_loss[2] += enc_loss.numpy()\n",
    "        del tape\n",
    "    print('[{}] Desc loss : {:.10f}\\t Gen Loss : {:.10f}\\t Enc Loss : {:.10f}'.format(epoch,running_loss[0],running_loss[1], running_loss[2] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    num_sample = 10\n",
    "    z_test = np.random.uniform(-1.0, 1.0, (num, )+latent_dim).astype(\"float32\")\n",
    "    #pred = gen.predict(z_test[:num_sample]).reshape(-1, img_dim, img_dim, 3)\n",
    "    pred = gen.predict(enc(X_train[0])).reshape(-1, img_dim, img_dim, 3)\n",
    "\n",
    "    _, axs = plt.subplots(2,num_sample, figsize=(24,12))\n",
    "    for i in range(num_sample):\n",
    "        img = np.clip((pred[i]+1)*(255.0/2), 0, 255).astype(\"uint32\")\n",
    "        #img = np.clip((pred[i]+1), 0, 2)\n",
    "        axs[0][i].imshow(img)\n",
    "        axs[0][i].tick_params(length=0, labelsize=0)\n",
    "        axs[1][i].tick_params(length=0, labelsize=0)\n",
    "        axs[1][i].imshow(X_train[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.save('model/generator')\n",
    "enc.save('model/enc')\n",
    "disc.save('model/desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed05aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
