{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9876024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72393d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9818d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,root_folder,transform):\n",
    "        self.transform=transform\n",
    "        self.img_folder=root_folder+'img/'\n",
    "\n",
    "        self.image_names=[i for i in os.listdir(self.img_folder) if '.jpg' in i]\n",
    "        self.attr = pd.read_csv(root_folder+'attr.csv').replace(-1,0)\n",
    "        _ = self.attr.pop('image_id')\n",
    "        \n",
    "        self.num_feat = len(self.attr.columns)\n",
    "        self.order = list(self.attr.columns)\n",
    "        \n",
    "        self.attr = self.attr.values\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.img_folder + self.image_names[index]\n",
    "        image=Image.open(image_path)\n",
    "        image=self.transform(image)\n",
    "        label = torch.tensor(self.attr[index])\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c961263d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_dim = 32\n",
    "batch_size = 2\n",
    "transform = Compose([Resize((img_dim, img_dim)),\n",
    "                     ToTensor(),\n",
    "                     Normalize(0,1)])\n",
    "\n",
    "training_data = ImageDataset(root_folder='sample_data/',transform=transform)\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63b2e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d81749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 40]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5e3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "997f8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, stride = 1,bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(negative_slope = 0.1),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 4, stride = 2,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope = 0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, stride = 2,bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope = 0.1),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, stride = 1,bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope = 0.1),\n",
    "            \n",
    "            nn.Conv2d(256, 2*z_dim, 2, stride = 1, bias=True)\n",
    "        )\n",
    "    def reparameterize(self, z):\n",
    "        z = z.view(z.size(0), -1)\n",
    "        mu, log_sigma = z[:, :self.z_dim], z[:, self.z_dim:]\n",
    "        std = torch.exp(log_sigma)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.reparameterize(z)\n",
    "        return z.view(x.size(0), self.z_dim, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7462e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channel = 3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1x = nn.Conv2d(num_channel, 32, 5, stride = 1, bias=False)\n",
    "        self.conv2x = nn.Conv2d(32, 64, 4, stride = 2, bias=False)\n",
    "        self.bn1x = nn.BatchNorm2d(64)\n",
    "        self.conv3x = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.bn2x =  nn.BatchNorm2d(128)\n",
    "        self.conv4x = nn.Conv2d(128, 256, 4, 2, 1, bias=False)\n",
    "        self.bn3x = nn.BatchNorm2d(256)\n",
    "        self.conv5x = nn.Conv2d(256, 512, 4, 2, 1, bias=False)\n",
    "        self.bn4x = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv1z = nn.Conv2d(z_dim, 512, 1, stride = 1, bias=False)\n",
    "        self.conv2z = nn.Conv2d(512, 512, 1, stride = 1, bias=False)\n",
    "        \n",
    "        self.conv1xz = nn.Conv2d(1024, 1024, 1, stride = 1, bias=False)\n",
    "        self.conv2xz = nn.Conv2d(1024, 1024, 1, stride = 1, bias=False)\n",
    "        self.conv3xz = nn.Conv2d(1024, 1, 1, stride = 1, bias=False)\n",
    "       \n",
    "    def forward(self, x, z):\n",
    "        x = F.leaky_relu(self.conv1x(x), negative_slope = 0.2)\n",
    "        x = F.leaky_relu(self.bn1x(self.conv2x(x)), negative_slope = 0.2)\n",
    "        x = F.leaky_relu(self.bn2x(self.conv3x(x)), negative_slope = 0.2)\n",
    "        x = F.leaky_relu(self.bn3x(self.conv4x(x)), negative_slope = 0.2)\n",
    "        x = F.leaky_relu(self.bn4x(self.conv5x(x)), negative_slope = 0.2)\n",
    "       \n",
    "        z = F.leaky_relu(self.conv1z(z), negative_slope = 0.2)\n",
    "        z = F.leaky_relu(self.conv2z(z), negative_slope = 0.2)\n",
    "    \n",
    "        xz = torch.cat((x,z), dim = 1)\n",
    "        \n",
    "        xz = F.leaky_relu(self.conv1xz(xz), negative_slope = 0.2)\n",
    "        xz = F.leaky_relu(self.conv2xz(xz), negative_slope = 0.2)\n",
    "        xz = F.leaky_relu(self.conv3xz(xz), negative_slope = 0.2)\n",
    "        \n",
    "        return xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8917d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorLatent(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(PriorLatent, self).__init__()\n",
    "        self.linear = nn.Linear(in_feat, out_feat)\n",
    "        \n",
    "    def forward(self, eps):\n",
    "        return F.relu(self.linear(eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddfa0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim, split = None, feat_num = None, num_channel = 3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.split = split\n",
    "        if self.split is None:\n",
    "            self.split = z_dim//2\n",
    "        self.output_bias = nn.Parameter(torch.zeros(3,img_dim, img_dim), requires_grad = True)\n",
    "        \n",
    "        self.prior = PriorLatent(self.split, feat_num)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, 256, 4, stride = 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, 4, stride = 2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, 4, stride = 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, 4, stride = 2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 32, 5, stride = 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 3, 1, stride = 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        eps, z_ = torch.split(z, split_size_or_sections = self.split, dim = 1)\n",
    "        z_trans = self.prior(eps)\n",
    "        print(z_trans.shape)\n",
    "        z = torch.cat(z_trans, z_, dim = 1)\n",
    "        \n",
    "        z = self.main(z)\n",
    "        out = z + self.output_bias\n",
    "        \n",
    "        return out, z_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a402404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1x): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "  (conv2x): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (bn1x): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3x): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn2x): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4x): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn3x): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5x): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn4x): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1z): Conv2d(100, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (conv2z): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (conv1xz): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (conv2xz): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (conv3xz): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_dim = 100\n",
    "\n",
    "g = Generator(z_dim, img_dim, split = 50, feat_num = 40).to(device)\n",
    "e = Encoder(z_dim).to(device)\n",
    "d = Discriminator().to(device)\n",
    "\n",
    "g.apply(weights_init)\n",
    "e.apply(weights_init)\n",
    "d.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ff3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "lr = 1e-4\n",
    "beta1 = 0.5\n",
    "\n",
    "ge_param = list(g.parameters())+list(e.parameters())\n",
    "\n",
    "opt_ge = optim.Adam(ge_param, lr = lr,  betas=(beta1, 0.999))\n",
    "opt_d = optim.Adam(d.parameters(), lr = lr,  betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22a7fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(fake):\n",
    "    with torch.no_grad():\n",
    "        fake = np.transpose(fake.cpu().numpy(), (0, 2, 3, 1))\n",
    "\n",
    "    _,ax = plt.subplots(1, 10, figsize=(24,4))\n",
    "    for i in range(10):\n",
    "        ax[i].imshow(fake[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfd85e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fd8368a6df47f193af05de615f4a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6892050984e54d81ac36d635b51dfefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "num_steps = len(train_dataloader.dataset)//batch_size\n",
    "\n",
    "clip_value = 1.2\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    ge_loss, d_loss = 0, 0\n",
    "    for step, (X, label) in tqdm(enumerate(train_dataloader), total=num_steps):\n",
    "        X = X.to(device)\n",
    "        print(X)\n",
    "        break\n",
    "        label = label.to(device)\n",
    "        print(label)\n",
    "        break\n",
    "        \n",
    "        y_true = Variable(torch.ones(X.size(0),1, dtype=torch.float).to(device), requires_grad = False)\n",
    "        y_fake = Variable(torch.zeros(X.size(0), 1, dtype=torch.float).to(device), requires_grad = False)\n",
    "        \n",
    "        noise1 = Variable(torch.Tensor(X.size()).normal_(0, 0.1 * (epochs - epoch) / epochs),requires_grad=False).to(device)\n",
    "        noise2 = Variable(torch.Tensor(X.size()).normal_(0, 0.1 * (epochs - epoch) / epochs),requires_grad=False).to(device)\n",
    "   \n",
    "        ######## TRAINING DISCRIMINATOR ###########\n",
    "        opt_d.zero_grad()\n",
    "\n",
    "        z_fake = Variable(torch.randn((X.size(0), z_dim, 1, 1)).to(device), requires_grad = False)\n",
    "        x_fake, latent = g(z_fake)\n",
    "\n",
    "        z_true = e(X)\n",
    "\n",
    "        out_true = d(X+noise1, z_true).view(X.shape[0],-1)\n",
    "        out_fake = d(x_fake+noise2, z_fake).view(X.shape[0],-1)\n",
    "\n",
    "        loss_d = torch.mean(F.softplus(-out_true)) + torch.mean(F.softplus(out_fake)) + criterion(latent, label)\n",
    "        loss_d.backward()\n",
    "        nn.utils.clip_grad_value_(d.parameters(), clip_value)\n",
    "        opt_d.step()\n",
    "            \n",
    "        ######## TRAINING GENERATOR AND ENCODER PART ###########\n",
    "            \n",
    "        opt_ge.zero_grad()\n",
    "            \n",
    "        z_fake = Variable(torch.randn((X.size(0), z_dim, 1, 1)).to(device), requires_grad = False)\n",
    "        x_fake, latent = g(z_fake)\n",
    "\n",
    "        z_true = e(X)\n",
    "\n",
    "        out_true = d(X+noise1, z_true).view(X.shape[0],-1)\n",
    "        out_fake = d(x_fake+noise2, z_fake).view(X.shape[0],-1)\n",
    "            \n",
    "        loss_ge = torch.mean(F.softplus(out_true)) + torch.mean(F.softplus(-out_fake))+ criterion(latent, label)\n",
    "        loss_ge.backward()\n",
    "        nn.utils.clip_grad_value_(ge_param, clip_value)\n",
    "        opt_ge.step()\n",
    "            \n",
    "        ge_loss += loss_ge.item()\n",
    "        d_loss += loss_d.item()\n",
    "        break\n",
    "            \n",
    "    print(f\"[{epoch+1}] D Loss : {d_loss/num_steps:>.5f} GE Loss : {ge_loss/num_steps:>.5f}\")\n",
    "    if epoch % 1 == 0:\n",
    "        z_fake = torch.randn((X.size(0), z_dim, 1, 1)).to(device)\n",
    "        plot_img(g(z_fake)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_fake = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
    "plot_img(g(z_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f693b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(g(e(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93904834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
